{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e5324-1b07-49a5-abbf-40c9d02f19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "\n",
    "#import the required packages\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4fa22-caf0-45db-8179-371d3898e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# +\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d4936-5fb3-4eb6-b426-6e33b77dff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 64, 64\n",
    "batch_size = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c1d53-032d-4299-bedc-a71e13e193ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  './MiriSegal',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  label_mode=None)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "for image_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  break\n",
    "\n",
    "tf.data.experimental.AUTOTUNE\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# +\n",
    "# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# -\n",
    "\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(scale= 1./127.5, offset=-1)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x: normalization_layer(x))\n",
    "image_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0d5e4-70f0-4439-84ba-f70d9542f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "noise_dim = (1,1,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de648f3-efeb-4f1e-bf88-ef581c8e66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    \n",
    "    inputs = keras.Input(shape=noise_dim, name='input_layer')\n",
    "    x = layers.Conv2DTranspose(64 * 8, kernel_size=4, strides= 4, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_transpose_1')(inputs)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_1')(x)\n",
    "    x = layers.ReLU(name='relu_1')(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64 * 4, kernel_size=4, strides= 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_transpose_2')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_2')(x)\n",
    "    x = layers.ReLU(name='relu_2')(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64 * 2, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_transpose_3')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8,  center=1.0, scale=0.02, name='bn_3')(x)\n",
    "    x = layers.ReLU(name='relu_3')(x)\n",
    "  \n",
    "\n",
    "    x = layers.Conv2DTranspose(64 * 1, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_transpose_4')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8,  center=1.0, scale=0.02, name='bn_4')(x)\n",
    "    x = layers.ReLU(name='relu_4')(x)\n",
    "    \n",
    "    outputs = layers.Conv2DTranspose(3, 4, 2,padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, activation='tanh', name='conv_transpose_5')(x)\n",
    "   \n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Generator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a47745-4a6b-40c8-84d6-a307d4374eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "generator.save('dcgan_gen.h5')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57c2fd-ebe1-4035-91df-614b9d2af7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    \n",
    "    inputs = keras.Input(shape=(64, 64, 3), name='input_layer')\n",
    "    x = layers.Conv2D(64, kernel_size=4, strides= 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_1')(inputs)\n",
    "    x = layers.LeakyReLU(0.2, name='leaky_relu_1')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64 * 2, kernel_size=4, strides= 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_2')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_1')(x)\n",
    "    x = layers.LeakyReLU(0.2, name='leaky_relu_2')(x)\n",
    "    \n",
    "    x = layers.Conv2D(64 * 4, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_3')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_2')(x)\n",
    "    x = layers.LeakyReLU(0.2, name='leaky_relu_3')(x)\n",
    "  \n",
    "\n",
    "    x = layers.Conv2D(64 * 8, 4, 2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, name='conv_4')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.1,  epsilon=0.8, center=1.0, scale=0.02, name='bn_3')(x)\n",
    "    x = layers.LeakyReLU(0.2, name='leaky_relu_4')(x)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, 4, 4,padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "    mean=0.0, stddev=0.02), use_bias=False, activation='sigmoid', name='conv_5')(x)\n",
    "    \n",
    "    outputs = layers.Flatten()(outputs)\n",
    "   \n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Discriminator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb983218-cebe-4e35-8f6f-e2fdd325c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "discriminator.save('dcgan_disc.h5')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c7dfc-5d60-4b8a-9c4f-32f538c7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def generator_loss(label, fake_output):\n",
    "    gen_loss = binary_cross_entropy(label, fake_output)\n",
    "    #print(gen_loss)\n",
    "    return gen_loss\n",
    "\n",
    "def discriminator_loss(label, output):\n",
    "    disc_loss = binary_cross_entropy(label, output)\n",
    "    #print(total_loss)\n",
    "    return disc_loss\n",
    "\n",
    "learning_rate = 0.0002 \n",
    "generator_optimizer = tf.keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999 )\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604ea3d-ff99-4f6f-a3d6-88af6cc6ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 25\n",
    "# We will reuse this seed overtime to visualize progress\n",
    "seed = tf.random.normal([num_examples_to_generate, 1, 1, latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d5b93-a968-4199-bcf6-57fff15fb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "# @tf.function\n",
    "def train_step(images, epoch):\n",
    "    # noise vector sampled from normal distribution\n",
    "    noise = tf.random.normal([BATCH_SIZE, 1, 1, latent_dim])\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    perf_real = real_output.numpy().mean()\n",
    "    generated_images = generator(noise, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "    perf_fake = fake_output.numpy().mean()\n",
    "    if perf_real > 0.8 and perf_fake < 0.4:\n",
    "        print('SKIPPING discriminator training, real data: %f, fake data: %f' % (perf_real, perf_fake))\n",
    "        skip_next = True\n",
    "    else:\n",
    "        print('Trying discriminator training, real data: %f, fake data: %f' % (perf_real, perf_fake))\n",
    "        skip_next = False\n",
    "\n",
    "    # we train discriminator only every 10th step to prevent it from being too strong\n",
    "    if not skip_next:\n",
    "        # Train Discriminator with real labels\n",
    "        with tf.GradientTape() as disc_tape1:\n",
    "            real_output = discriminator(images, training=True)\n",
    "            perf_real = real_output.numpy().mean()\n",
    "            print('real data: ',perf_real)\n",
    "            real_targets = tf.ones_like(real_output)\n",
    "            disc_loss1 = discriminator_loss(real_targets, real_output)\n",
    "        # gradient calculation for discriminator for real labels    \n",
    "        gradients_of_disc1 = disc_tape1.gradient(disc_loss1, discriminator.trainable_variables)\n",
    "\n",
    "        # parameters optimization for discriminator for real labels   \n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_disc1,\\\n",
    "        discriminator.trainable_variables))\n",
    "\n",
    "        # Train Discriminator with fake labels\n",
    "        with tf.GradientTape() as disc_tape2:\n",
    "            fake_output = discriminator(generated_images, training=True)\n",
    "            fake_targets = tf.zeros_like(fake_output)\n",
    "            disc_loss2 = discriminator_loss(fake_targets, fake_output)\n",
    "            perf_fake = fake_output.numpy().mean()\n",
    "            print('fake data: ',perf_fake)\n",
    "        # gradient calculation for discriminator for fake labels \n",
    "        gradients_of_disc2 = disc_tape2.gradient(disc_loss2, discriminator.trainable_variables)\n",
    "\n",
    "        # parameters optimization for discriminator for fake labels        \n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_disc2,\\\n",
    "        discriminator.trainable_variables))\n",
    "    \n",
    "    # Train Generator with real labels\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        real_targets = tf.ones_like(fake_output)\n",
    "        gen_loss = generator_loss(real_targets, fake_output)\n",
    "\n",
    "    # gradient calculation for generator for real labels     \n",
    "    gradients_of_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    \n",
    "    # parameters optimization for generator for real labels\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_gen,\\\n",
    "    generator.trainable_variables))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e8e3d-d24d-44db-aea5-5e7de6f10ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        D_loss_list, G_loss_list = [], []\n",
    "        for image_batch in dataset:\n",
    "            i += 1\n",
    "            skip_next = train_step(image_batch, epoch)\n",
    "        print(epoch)\n",
    "        if epoch % 50 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "            generate_and_save_images(generator,\n",
    "                                  epoch + 1,\n",
    "                                  seed)\n",
    "            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            generator.save_weights('training_weights/gen_'+ str(epoch)+'.h5')\n",
    "            discriminator.save_weights('training_weights/disc_'+ str(epoch)+'.h5')    \n",
    "\n",
    "    # Generate after the final epoch\n",
    "#     display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                            epochs,\n",
    "                            seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a51cf1-54ea-4097-9cf0-fa17371f3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "    print(predictions.shape)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        pred = (predictions[i, :, :, :] + 1 ) * 127.5\n",
    "        pred = np.array(pred)  \n",
    "        plt.imshow(pred.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "    plt.savefig('images/image_at_epoch_{:d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d154c-a6e5-4a0c-a02e-882bdaad8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(normalized_ds, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9b5d2-58c1-4676-b5f8-892b776bb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='constant', cval=1.0)\n",
    "for a in normalized_ds.take(-1):\n",
    "    pass\n",
    "dg = datagen.flow(a,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10181f6-cfd4-4552-a294-c325686338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        D_loss_list, G_loss_list = [], []\n",
    "        for ii in range(3):\n",
    "            image_batch = dataset.next()\n",
    "            i += 1\n",
    "            skip_next = train_step(image_batch, epoch)\n",
    "        print(epoch)\n",
    "        if epoch % 50 ==0:\n",
    "            display.clear_output(wait=True)\n",
    "            generate_and_save_images(generator,\n",
    "                                  epoch + 1,\n",
    "                                  seed)\n",
    "            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "        # Save the model every 50 epochs\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            generator.save_weights('training_weights/gen_'+ str(epoch)+'.h5')\n",
    "            discriminator.save_weights('training_weights/disc_'+ str(epoch)+'.h5')    \n",
    "\n",
    "    # Generate after the final epoch\n",
    "#     display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                            epochs,\n",
    "                            seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03b5c4-6609-481b-a5c3-fcbeffb5b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2(dg, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
